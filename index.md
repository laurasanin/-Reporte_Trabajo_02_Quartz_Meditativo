# Fusi√≥n de Perspectivas: Registro y Medici√≥n M√©trica en una Escena Real

**Curso:** Visi√≥n por Computador (3009228)  
**Semestre:** 2025-02  
**Facultad de Minas ‚Äî Universidad Nacional de Colombia**  
**Departamento de Ciencias de la Computaci√≥n y de la Decisi√≥n**  
**Autor:** [Tu nombre aqu√≠]  

---

## üü© Introducci√≥n

El registro de im√°genes es una tarea fundamental en visi√≥n por computador, cuyo prop√≥sito es alinear diferentes vistas de una misma escena para obtener una representaci√≥n coherente y continua. Este proceso es esencial en aplicaciones como la fotogrametr√≠a, la reconstrucci√≥n 3D, el mapeo y la medici√≥n de objetos en el mundo real.

En este trabajo se implementa un pipeline de **registro y fusi√≥n de im√°genes** empleando descriptores locales (SIFT, ORB y AKAZE), estimaci√≥n de **homograf√≠as mediante RANSAC**, y t√©cnicas de blending para lograr un panorama unificado. Posteriormente, a partir de la escena fusionada, se realiza una **calibraci√≥n m√©trica** usando objetos de referencia para estimar distancias reales dentro del entorno.

El proyecto combina validaci√≥n con im√°genes sint√©ticas ‚Äîpara evaluar la robustez geom√©trica del m√©todo‚Äî y aplicaci√≥n pr√°ctica en un conjunto de fotograf√≠as de un comedor real, donde se cuantifican errores, se analizan resultados y se discuten las limitaciones del m√©todo.

---

## üß† Marco Te√≥rico

### Registro de Im√°genes
El registro consiste en encontrar una transformaci√≥n geom√©trica que alinee dos im√°genes capturadas desde diferentes puntos de vista. En este caso, se asume que las vistas pertenecen a un mismo plano, por lo que la transformaci√≥n se modela mediante una **homograf√≠a 3√ó3**.

### Detecci√≥n y Descripci√≥n de Caracter√≠sticas
Los detectores y descriptores locales permiten identificar puntos de inter√©s invariantes ante cambios de escala, rotaci√≥n e iluminaci√≥n:
- **SIFT (Lowe, 2004)**: robusto a rotaciones y escalas.
- **ORB (Rublee et al., 2011)**: eficiente y r√°pido, basado en BRIEF binario.
- **AKAZE (Alcantarilla et al., 2013)**: balance entre robustez y velocidad mediante detecci√≥n en el espacio no lineal.

### Emparejamiento y Filtrado
Los descriptores se comparan usando m√©tricas de distancia (L2 o Hamming) y se filtran con el **ratio test** (Lowe, 2004). Para reducir falsos emparejamientos se aplica **validaci√≥n cruzada** y posteriormente **RANSAC** (Fischler & Bolles, 1981) para estimar la homograf√≠a rechazando outliers.

### Fusi√≥n y Blending
Una vez estimada la transformaci√≥n, las im√°genes se combinan mediante interpolaci√≥n y blending (por ejemplo, *feather blending* o pir√°mides Laplacianas) para generar un mosaico continuo.

### Calibraci√≥n M√©trica
Al identificar objetos de dimensiones conocidas dentro de la imagen fusionada, se establece una relaci√≥n **p√≠xeles ‚Üî cent√≠metros**, permitiendo estimar medidas reales a partir del modelo 2D registrado.

---

## üß≠ Metodolog√≠a

El desarrollo sigui√≥ un flujo modular documentado en tres notebooks principales:

1. `01_exploratory_analysis.ipynb` ‚Äì An√°lisis exploratorio y comparaci√≥n de detectores.  
2. `02_synthetic_validation.ipynb` ‚Äì Validaci√≥n geom√©trica con im√°genes sint√©ticas.  
3. `03_main_pipeline.ipynb` ‚Äì Registro, fusi√≥n, calibraci√≥n y medici√≥n en la escena real.

### Pipeline de procesamiento

1. **Extracci√≥n de caracter√≠sticas** con SIFT, ORB y AKAZE.  
2. **Emparejamiento de descriptores** mediante BFMatcher o FLANN con *ratio test*.  
3. **Estimaci√≥n de homograf√≠a** con RANSAC.  
4. **Fusi√≥n y blending** de las im√°genes alineadas.  
5. **Calibraci√≥n m√©trica** con referencias f√≠sicas (cuadro y mesa).  
6. **Medici√≥n y an√°lisis de incertidumbre.**

### Decisiones t√©cnicas
- **SIFT** se us√≥ como detector principal por su robustez.  
- Umbral de *ratio test* = 0.75.  
- RANSAC: 2000 iteraciones, umbral 5 px.  
- Blending: m√©todo *feather* para suavizar transiciones.  
- Escala calibrada: 9.32 p√≠xeles/cm.  
- Referencias: cuadro (117 cm) y mesa (161.1 cm).  

### Diagrama de flujo

```mermaid
flowchart LR
    A[Im√°genes de entrada] --> B[Detecci√≥n de caracter√≠sticas]
    B --> C[Emparejamiento robusto (RANSAC)]
    C --> D[Fusi√≥n de im√°genes]
    D --> E[Panorama final]
    E --> F[Calibraci√≥n m√©trica]
    F --> G[Mediciones y an√°lisis]
```

---

## üß™ Resultados

### Im√°genes de entrada
![Im√°genes originales](01_original_images.jpeg)

### Comparaci√≥n de detectores
![Comparaci√≥n de detectores](02_detector_comparison.jpeg)

### Distribuci√≥n de keypoints
![Distribuci√≥n de keypoints](04_keypoint_distribution.jpeg)

### Emparejamientos v√°lidos
![Matches 1-2](03_matches_img1_to_img2.jpeg)
![Matches 2-3](03_matches_img2_to_img3.jpeg)

### Validaci√≥n con im√°genes sint√©ticas
![Dataset sint√©tico](05_synthetic_dataset.png)
![Errores de validaci√≥n](06_validation_errors.png)
![Errores por esquina](07_corner_errors.png)

### Fusi√≥n de perspectivas
![Panorama final](08_panorama_final.jpeg)

### Calibraci√≥n y medici√≥n
![Reporte de mediciones](09_measurement_report.png)

---

## üîç Discusi√≥n

- **Desempe√±o de detectores:** SIFT ofrece la mejor relaci√≥n entre densidad y estabilidad; ORB destaca por eficiencia pero reduce correspondencias v√°lidas.  
- **Precisi√≥n geom√©trica:** El modelo homogr√°fico reconstruye correctamente el plano de la escena, con errores esperables por paralaje y variaci√≥n de punto de vista.  
- **Blending:** El m√©todo *feather* logr√≥ una transici√≥n suave entre im√°genes, sin artefactos notables.  
- **Medici√≥n:** La calibraci√≥n manual permiti√≥ obtener escalas coherentes, aunque la incertidumbre indica sensibilidad a la selecci√≥n de puntos.  
- **Limitaciones:** Las principales fuentes de error son la falta de control de iluminaci√≥n, peque√±as deformaciones por perspectiva no coplanar y la ausencia de puntos de control autom√°ticos.

---

## ‚úÖ Conclusiones

1. El pipeline de registro basado en **SIFT + RANSAC + homograf√≠a** permiti√≥ fusionar exitosamente las tres im√°genes del comedor en un panorama coherente.  
2. La **validaci√≥n sint√©tica** confirm√≥ la precisi√≥n del modelo geom√©trico, con errores promedio aceptables.  
3. La **calibraci√≥n m√©trica** demostr√≥ la viabilidad de estimar dimensiones reales a partir de una imagen registrada.  
4. Se identificaron oportunidades de mejora mediante la incorporaci√≥n de **bundle adjustment** y m√©todos de calibraci√≥n autom√°tica.  
5. El ejercicio permiti√≥ comprender integralmente las etapas del registro, desde la detecci√≥n hasta la medici√≥n m√©trica aplicada.

---

## üìö Referencias

- Lowe, D. G. (2004). *Distinctive Image Features from Scale-Invariant Keypoints*. International Journal of Computer Vision, 60(2), 91‚Äì110.  
- Hartley, R., & Zisserman, A. (2003). *Multiple View Geometry in Computer Vision* (2nd ed.). Cambridge University Press.  
- Fischler, M. A., & Bolles, R. C. (1981). *Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography*. Communications of the ACM, 24(6), 381‚Äì395.  
- Rublee, E., Rabaud, V., Konolige, K., & Bradski, G. (2011). *ORB: An Efficient Alternative to SIFT or SURF*. IEEE International Conference on Computer Vision (ICCV), 2564‚Äì2571.  
- Alcantarilla, P. F., Nuevo, J., & Bartoli, A. (2013). *Fast Explicit Diffusion for Accelerated Features in Nonlinear Scale Spaces*. British Machine Vision Conference (BMVC).  

---

## üë• Contribuci√≥n Individual

| Integrante | Rol | Actividad principal |
|-------------|-----|---------------------|
| [Nombre A] | Desarrollo | Implementaci√≥n del pipeline y scripts de validaci√≥n |
| [Nombre B] | An√°lisis | Evaluaci√≥n de detectores y redacci√≥n de resultados |
| [Nombre C] | Visualizaci√≥n | Dise√±o de figuras y reporte de mediciones |

---

**Repositorio del proyecto:** [https://github.com/TU_USUARIO/fusion-perspectivas](#)  
**Publicaci√≥n:** [https://TU_USUARIO.github.io/fusion-perspectivas](#)
